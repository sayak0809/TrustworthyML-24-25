{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Trustworthy Machine Learning**\n\n---\n**Winter Semester 2024-2025**\n \n**Lecturer**: Seong Joon Oh\n \n**Tutor**: Ankit Sonthalia\n\n---\n \n**Exercise 2 -- XAI**\n\n---\nGroup number: ***Insert Here***\n\nStudent names: ***Insert Here***\n\nStudent emails: ***Insert Here***\n\n---\n**The deadline for this homework is on 11/12/2024 at 23:59.**\n\nThis is a **group exercise**. After we grade your submissions, all members of any given group will receive the same grade. Please report cases where any team member contributes significantly less than the other members of the same group. Like the first exercise, the grade from this exercise will count towards the final grade.\n\n---\n### Structure\nThis homework covers 2 broad topics. It makes sense to start working on each topic after attending the corresponding lecture. The recommendeded starting dates are indicated in the section headers, but feel free to explore by yourself too.\n\n**How to find the parts that you need to edit?**\n\n1. Parts where you need to write code are marked as\n   ```\n   #### >>>> PUT YOUR SOLUTION HERE <<<<\n   #### >>>> END OF YOUR SOLUTION <<<<\n   ```\n2. Parts where you need to answer questions are marked as\n   ```TODO your answer:```.\n\n**Do not use any other external libraries than the ones already defined in the notebook. If you're unsure, consult the TML lecture staff first about usage.**\n\nIf you have any questions about the homework, feel free to drop us a message on Discord or come to the tutorials on Thursdays at 14:00. The lead tutor for this homework is [Ankit](https://scalabletrustworthyai.github.io/member/ankit/).\n\n#### **How to use GPUs on Kaggle**\n- Verify your phone number.\n- Select your preferred GPU at `Settings > Accelerator`.\n- Put parameters and tensors on CUDA via `tensor.to(device)` etc.\n- Double check if the parameters and tensors are on CUDA via `tensor.device` etc.\n\n#### Note on Kaggle\n\nWe provide our exercise notebooks on Kaggle because of Kaggle's generous free GPU policy. After phone number verification, one receives 30 hours of free GPU usage per week. This translates to 90 hours per week for a group of three. We find this to be much better than Google Colab, where one does not even know how much compute they are left with. However, if you do not wish to use Kaggle for some reason, please feel free to use any other platform that is available to you -- ultimately, you only need to submit the final notebook to us. There are no specific Kaggle dependencies in this exercise; however, in the rare event that you run into some minor python package issues, please reach out to the TML staff for help.\n\n\n#### **Submission**\n\n(1) Click on `File > Download notebook`;\n\n(2) Send the `.ipynb` file to `stai.there@gmail.com` before the deadline.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## 1 Explaining predictions with feature attribution\n\nIn this section, you will evaluate and compare popular feature attribution (FA) methods on vision models. \n\nWe will start by setting up the pre-requisites.\n\n1. A LeNet model pre-trained on Fashion-MNIST  (~90% test set accuracy).\n2. The Fashion-MNIST dataset.\n\nWe will also perform some sanity checks along the way.\n\n**Plan**\n\n**1.1** You will implement a remove-and-classify approach for evaluating FA methods. We provide a dummy feature attribution explanation (a centered Gaussian). Please use this to test your remove-and-classify function.\n\n**1.2** You will test two feature attribution methods using the remove-and-classify function you designed above. \n\n**1.3** Discussion: you will answer some questions.\n\n**Recommended start**: 14.11.2024\n","metadata":{}},{"cell_type":"markdown","source":"## 1.0 Prerequisites","metadata":{}},{"cell_type":"code","source":"# Set the seed for reproducibility\nimport os, sys\nimport torch\ntorch.manual_seed(2024)\n\n# Make sure you are using cuda\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nprint(f\"Device in use: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T18:30:31.510377Z","iopub.execute_input":"2024-11-20T18:30:31.510746Z","iopub.status.idle":"2024-11-20T18:30:31.521054Z","shell.execute_reply.started":"2024-11-20T18:30:31.510713Z","shell.execute_reply":"2024-11-20T18:30:31.520105Z"}},"outputs":[{"name":"stdout","text":"Device in use: cuda\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"# Install utilities\n\n!pip install git+https://github.com/aktsonthalia/tml2425_xai\n!git clone https://huggingface.co/aktsonthalia2/tml2425_xai_models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T18:30:31.522563Z","iopub.execute_input":"2024-11-20T18:30:31.522888Z","iopub.status.idle":"2024-11-20T18:30:41.899751Z","shell.execute_reply.started":"2024-11-20T18:30:31.522861Z","shell.execute_reply":"2024-11-20T18:30:41.898868Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/aktsonthalia/tml2425_xai\n  Cloning https://github.com/aktsonthalia/tml2425_xai to /tmp/pip-req-build-qteu70jh\n  Running command git clone --filter=blob:none --quiet https://github.com/aktsonthalia/tml2425_xai /tmp/pip-req-build-qteu70jh\n  Resolved https://github.com/aktsonthalia/tml2425_xai to commit 7eda89a7e042e8ec7539584d2e753e42b5f7afef\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hfatal: destination path 'tml2425_xai_models' already exists and is not an empty directory.\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"# Load the pre-trained model\n\nfrom tml2425_xai.lenet import LeNet\nlenet = torch.load(f\"tml2425_xai_models/lenet_fashionmnist.pckl\", map_location=device)\nlenet.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T18:30:41.901087Z","iopub.execute_input":"2024-11-20T18:30:41.901368Z","iopub.status.idle":"2024-11-20T18:30:41.916939Z","shell.execute_reply.started":"2024-11-20T18:30:41.901342Z","shell.execute_reply":"2024-11-20T18:30:41.916157Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/399408301.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  lenet = torch.load(f\"tml2425_xai_models/lenet_fashionmnist.pckl\", map_location=device)\n","output_type":"stream"},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"LeNet(\n  (conv1): Conv2d(1, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n  (conv2): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n  (linear1): Linear(in_features=6272, out_features=100, bias=True)\n  (linear2): Linear(in_features=100, out_features=10, bias=True)\n)"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"# Load the dataset. \n# Since the model is already trained, we only require the test set.\n\nfrom torchvision import transforms\nfrom torchvision import datasets\nfrom torch.utils.data import DataLoader\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Lambda(lambda x: x.squeeze())\n])\n\nfmnist_test = datasets.FashionMNIST(\n    root='./data_FashionMNIST',\n    train=False,\n    download=True,\n    transform=transform\n)\n\n# Sanity checks\nassert len(fmnist_test) == 10000\nx, y = fmnist_test[0]\nassert x.shape == (28, 28)\nassert isinstance(y, int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T18:30:41.918923Z","iopub.execute_input":"2024-11-20T18:30:41.919166Z","iopub.status.idle":"2024-11-20T18:30:41.938369Z","shell.execute_reply.started":"2024-11-20T18:30:41.919142Z","shell.execute_reply":"2024-11-20T18:30:41.937570Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# Visualize some examples from the dataset\n\nimport matplotlib.pyplot as plt\n\ndef show_samples(dataset, num_samples=4, indices=None):\n    plt.figure(figsize=(12, 4))\n\n    if indices is None: indices = range(num_samples)\n    for idx, i in enumerate(indices):\n        image, _ = dataset[i]\n        image = image.detach().cpu().numpy()\n        if image.shape[0] == 1 or image.shape[0] == 3:\n            image = image.transpose(1, 2, 0)\n        plt.subplot(2, 4, idx + 1)\n        plt.imshow(image.squeeze(), cmap='gray')\n        plt.axis('off')\n    plt.show()\n\nshow_samples(fmnist_test, num_samples=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T18:30:41.939294Z","iopub.execute_input":"2024-11-20T18:30:41.939523Z","iopub.status.idle":"2024-11-20T18:30:42.498864Z","shell.execute_reply.started":"2024-11-20T18:30:41.939499Z","shell.execute_reply":"2024-11-20T18:30:42.496946Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x400 with 8 Axes>","image/png":"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"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"# Sanity check: verify that the correct model was loaded. \n# Accuracy should be 0.9.\n\nfrom tml2425_xai.xai_utils import model_accuracy\n\nfmnist_accuracy = model_accuracy(lenet, fmnist_test)\nassert fmnist_accuracy == 0.9\nprint(f'Accuracy on the test set: {fmnist_accuracy:.3f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T18:30:42.500183Z","iopub.execute_input":"2024-11-20T18:30:42.500623Z","iopub.status.idle":"2024-11-20T18:30:45.106047Z","shell.execute_reply.started":"2024-11-20T18:30:42.500573Z","shell.execute_reply":"2024-11-20T18:30:45.105165Z"}},"outputs":[{"name":"stdout","text":"Accuracy on the test set: 0.900\n","output_type":"stream"}],"execution_count":51},{"cell_type":"markdown","source":"Everything works. Great! Next, it's your turn.","metadata":{}},{"cell_type":"markdown","source":"## 1.1 Designing the feature attribution evaluation function (10 pts)\n\nFirst, you will write Python code for evaluating the correctness of a feature attribution explanation with a remove-and-classify approach. In our case, each \"feature\" is a pixel location. An \"explanation\" ranks the pixel locations in decreasing order of their importance towards the model's predictions. Then, in order to evaluate the explanation, we remove the pixels in the sequence that the explanation ranks them, and look at the drop in the model's performance. This is what we mean when we say \"remove-and-classify\". \n\nAfter you have written your function for evaluating explanations, you will test it on a dummy explanation (a centred 2D Gaussian over the input image). \n\nSince removing a feature at a time is slow, we instead remove 100 features in each removal step. \n\n**Interpretation**: If removing the most important pixels (according to the explanation) causes the steepest drop in the model's performances, the explanation can be deemed as a good one. \n\nLet's visualize an attribution map to make sure we understand what we are doing.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef show_attribution_overlay(image, attribution_map, alpha=0.5):\n    \"\"\"\n    Displays an image with an attribution map overlay.\n    \n    Parameters:\n    - image: The original image as a 2D numpy array or PyTorch tensor.\n    - attribution_map: The attribution map as a 2D numpy array or PyTorch tensor, same size as image.\n    - alpha: Transparency level for the overlay. (0 = fully transparent, 1 = fully opaque)\n    \"\"\"\n    # Convert image and attribution_map to numpy arrays if they are tensors\n    if isinstance(image, torch.Tensor):\n        image = image.squeeze().cpu().numpy()\n        if image.shape[0] == 1 or image.shape[0] == 3:\n            image = image.transpose(1, 2, 0)\n    if isinstance(attribution_map, torch.Tensor):\n        attribution_map = attribution_map.squeeze().cpu().numpy()\n    \n    # Display the image\n    plt.imshow(image, cmap='gray')\n    \n    # Overlay the attribution map with a color map\n    plt.imshow(attribution_map, cmap='jet', alpha=alpha)\n    plt.colorbar(label=\"Attribution Intensity\")\n    \n    # Remove axis and display\n    plt.axis('off')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T18:47:21.612341Z","iopub.execute_input":"2024-11-20T18:47:21.613126Z","iopub.status.idle":"2024-11-20T18:47:21.619019Z","shell.execute_reply.started":"2024-11-20T18:47:21.613095Z","shell.execute_reply":"2024-11-20T18:47:21.618028Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"from tml2425_xai.xai_utils import centered_gaussian\n\nidx = 25\ngaussian_explanations = torch.zeros((len(fmnist_test), 28, 28))\nfor i in range(len(fmnist_test)):\n    gaussian_explanations[i] = torch.tensor(centered_gaussian(28, 28))\nshow_attribution_overlay(fmnist_test.data[idx], gaussian_explanations[idx])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T18:47:40.352974Z","iopub.execute_input":"2024-11-20T18:47:40.353760Z","iopub.status.idle":"2024-11-20T18:47:46.488215Z","shell.execute_reply.started":"2024-11-20T18:47:40.353729Z","shell.execute_reply":"2024-11-20T18:47:46.487235Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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"},"metadata":{}}],"execution_count":65},{"cell_type":"markdown","source":"**Your turn! Fill in the remove-and-classify function below to evaluate how well the dummy gaussian maps explain the model predictions.**\n\n**Hint:** Try to vectorize your code as much as possible. The slowest possible implementation of this function will take 25 minutes to run on the CUB dataset, while a decently fast one will finish in under a minute. Enough said! :)","metadata":{}},{"cell_type":"code","source":"# TODO: 10 points\n\nfrom sklearn.metrics import auc\nimport torch\nfrom tqdm import tqdm\n\n# This is a tip, you don't have to split up the code into two functions.\n# Having them separate makes your code more readable.\ndef sort_explanations_by_importance(explanations):\n    \"\"\"For each feature map in the explanations list, returns the indices\n    that would sort the pixels according to the attribution. Most important\n    feature is assigned index 0 and so on.\n\n    :param explanations: list of feature attribution maps\n    :returns: list of explanation ranks\n    \"\"\"\n    #### >>>> PUT YOUR SOLUTION HERE <<<<\n    \n    sorted_ranks = [torch.argsort(-explanation.view(-1)) for explanation in explanations]\n    return sorted_ranks\n    \n#### >>>> END OF YOUR SOLUTION <<<<\n    \ndef remove_and_classify(model, dataset, explanations, k=100):\n    \"\"\"Main remove-and-classify function. Iteratively removes the top k features\n    (k, k*2, k*3 until none are left) from all instances in the dataset and\n    measures model performance.\n    Returns the list of model performances after each removal step.\n    :param model: Model to explain\n    :param dataset: Image data\n    :param explanations: list of explanations corresponding to the dataset. \n    :param k: number of features to remove at once, initialized at 100\n    :returns: list of model accuracy at removal of k features.\n    \"\"\"\n    \n    # input check\n    assert len(dataset) == len(explanations) # one explanation per sample\n    assert dataset.data.shape[-2:] == explanations[0].shape # each explanation is essentially a pixel importance map\n    total_num_features = explanations[0].numel()\n\n    sorted_attribution_ranks = sort_explanations_by_importance(explanations)\n    performances = []\n\n    # Unifying processing across two datasets (you will see why later).\n    data_shape = dataset[0][0].shape # should be the same of an image\n    if len(data_shape) == 2: # fmnist data - grayscale\n        width, height = data_shape\n        data_iterable = dataset.data\n        # Access the fmnist data as data_iterable[index][row, column]\n    elif len(data_shape) == 3: # cub data\n        channels, width, height = data_shape\n        data_iterable = dataset\n        # Access the cub data as data_iterable[index][0][channel, row, column]\n        # We advise you to implement feature removal in-place. This is not\n        # good coding practice, but otherwise you might run out of RAM.\n\n    #### >>>> PUT YOUR SOLUTION HERE <<<<\n    for step in range(k, total_num_features + 1, k):\n        current_data = data_iterable.clone() \n        \n        for idx, ranks in enumerate(sorted_attribution_ranks):\n            to_remove = ranks[:step]  \n            \n            rows, cols = to_remove // current_data.size(-1), to_remove % current_data.size(-1)\n            current_data[idx, rows, cols] = 0  \n\n        # Now classify and measure performance on the modified data\n        current_dataset = torch.utils.data.TensorDataset(current_data.unsqueeze(1), dataset.targets)\n        current_loader = torch.utils.data.DataLoader(current_dataset, batch_size=128, shuffle=False)\n\n        correct = 0\n        total = 0\n        model.eval()\n        with torch.no_grad():\n            for inputs, labels in current_loader:\n                outputs = model(inputs)\n                _, predicted = outputs.max(1)\n                correct += (predicted == labels).sum().item()\n                total += labels.size(0)\n\n        performances.append(correct / total)\n    #### >>>> END OF YOUR SOLUTION <<<<\n\n    return performances","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T19:26:41.727778Z","iopub.execute_input":"2024-11-20T19:26:41.728487Z","iopub.status.idle":"2024-11-20T19:26:41.739506Z","shell.execute_reply.started":"2024-11-20T19:26:41.728447Z","shell.execute_reply":"2024-11-20T19:26:41.738573Z"}},"outputs":[],"execution_count":75},{"cell_type":"markdown","source":"Run your evaluation code on the test set with the dummy explanations and get the removal performances.\nThis takes about 1-3 minutes, depending on the GPU you were assigned.","metadata":{}},{"cell_type":"code","source":"# the remove-and-classify function performs changes in-place, \n# so we load the dataset again \n# in order to make the operations in this cell idempotent\nfmnist_test = datasets.FashionMNIST(\n    root='./data_FashionMNIST',\n    train=False,\n    download=True,\n    transform=transform\n)\n\nk = 100\ngaussian_explanations.shape\nremoval_performances = remove_and_classify(lenet, fmnist_test, gaussian_explanations, k)\nremoval_performances.insert(0, fmnist_accuracy) # in place, adding the original accuracy in front for AUC","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T19:26:47.462376Z","iopub.execute_input":"2024-11-20T19:26:47.463214Z","iopub.status.idle":"2024-11-20T19:26:47.813350Z","shell.execute_reply.started":"2024-11-20T19:26:47.463180Z","shell.execute_reply":"2024-11-20T19:26:47.812232Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[76], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     12\u001b[0m gaussian_explanations\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 13\u001b[0m removal_performances \u001b[38;5;241m=\u001b[39m \u001b[43mremove_and_classify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlenet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmnist_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgaussian_explanations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m removal_performances\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, fmnist_accuracy) \u001b[38;5;66;03m# in place, adding the original accuracy in front for AUC\u001b[39;00m\n","Cell \u001b[0;32mIn[75], line 60\u001b[0m, in \u001b[0;36mremove_and_classify\u001b[0;34m(model, dataset, explanations, k)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# Access the cub data as data_iterable[index][0][channel, row, column]\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# We advise you to implement feature removal in-place. This is not\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# good coding practice, but otherwise you might run out of RAM.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m#### >>>> PUT YOUR SOLUTION HERE <<<<\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k, total_num_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, k):\n\u001b[0;32m---> 60\u001b[0m     current_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata_iterable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m() \n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, ranks \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sorted_attribution_ranks):\n\u001b[1;32m     63\u001b[0m         to_remove \u001b[38;5;241m=\u001b[39m ranks[:step]  \n","\u001b[0;31mAttributeError\u001b[0m: 'FashionMNIST' object has no attribute 'clone'"],"ename":"AttributeError","evalue":"'FashionMNIST' object has no attribute 'clone'","output_type":"error"}],"execution_count":76},{"cell_type":"markdown","source":"Next, we plot the model performance as features are removed. We also put a quantifiable number to our evaluation. The lower the RAC score, the better we deem our explanation to be.","metadata":{}},{"cell_type":"code","source":"# To get the remove-and-classify score, plot the removal performances for analysis\n# also get the AUC of the plot \nimport matplotlib.pyplot as plt\nrac_score = auc(range(len(removal_performances)), removal_performances)\nrac_score_norm = rac_score / auc(range(len(removal_performances)), [fmnist_accuracy]*len(removal_performances))\nprint(f\"The remove and classify score is {rac_score_norm: .3f}\")\n\nplt.plot(removal_performances)\nplt.grid()\nplt.ylabel('Model accuracy')\nplt.xlabel('Feature removal step (k=100)')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T17:49:58.311472Z","iopub.execute_input":"2024-11-20T17:49:58.312280Z","iopub.status.idle":"2024-11-20T17:49:58.381735Z","shell.execute_reply.started":"2024-11-20T17:49:58.312248Z","shell.execute_reply":"2024-11-20T17:49:58.380656Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[43], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# To get the remove-and-classify score, plot the removal performances for analysis\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# also get the AUC of the plot \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m rac_score \u001b[38;5;241m=\u001b[39m \u001b[43mauc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremoval_performances\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremoval_performances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m rac_score_norm \u001b[38;5;241m=\u001b[39m rac_score \u001b[38;5;241m/\u001b[39m auc(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(removal_performances)), [fmnist_accuracy]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(removal_performances))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe remove and classify score is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrac_score_norm\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:90\u001b[0m, in \u001b[0;36mauc\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     87\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least 2 points are needed to compute area under curve, but x.shape = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;241m%\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     93\u001b[0m     )\n\u001b[1;32m     95\u001b[0m direction \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     96\u001b[0m dx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdiff(x)\n","\u001b[0;31mValueError\u001b[0m: At least 2 points are needed to compute area under curve, but x.shape = 0"],"ename":"ValueError","evalue":"At least 2 points are needed to compute area under curve, but x.shape = 0","output_type":"error"}],"execution_count":43},{"cell_type":"code","source":"# the remove-and-classify function performs changes in-place, \n# so we load the dataset again \n# in order to make the operations in this cell idempotent\nfmnist_test = datasets.FashionMNIST(\n    root='./data_FashionMNIST',\n    train=False,\n    download=True,\n    transform=transform\n)\n\nk = 100\ngaussian_explanations.shape\nremoval_performances = remove_and_classify(lenet, fmnist_test, gaussian_explanations, k)\nremoval_performances.insert(0, fmnist_accuracy) # in place, adding the original accuracy in front for AUC","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T18:41:46.861413Z","iopub.execute_input":"2024-11-20T18:41:46.862214Z","iopub.status.idle":"2024-11-20T18:41:47.569967Z","shell.execute_reply.started":"2024-11-20T18:41:46.862178Z","shell.execute_reply":"2024-11-20T18:41:47.568598Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[56], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     12\u001b[0m gaussian_explanations\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 13\u001b[0m removal_performances \u001b[38;5;241m=\u001b[39m \u001b[43mremove_and_classify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlenet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmnist_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgaussian_explanations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m removal_performances\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, fmnist_accuracy) \u001b[38;5;66;03m# in place, adding the original accuracy in front for AUC\u001b[39;00m\n","Cell \u001b[0;32mIn[55], line 62\u001b[0m, in \u001b[0;36mremove_and_classify\u001b[0;34m(model, dataset, explanations, k)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m current_loader:\n\u001b[0;32m---> 62\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m         _, predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     64\u001b[0m         correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predicted \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tml2425_xai/lenet.py:35\u001b[0m, in \u001b[0;36mLeNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# CL1:   \u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# MP1: \u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (unsigned char) and bias type (float) should be the same"],"ename":"RuntimeError","evalue":"Input type (unsigned char) and bias type (float) should be the same","output_type":"error"}],"execution_count":56},{"cell_type":"code","source":"# Clearing memory in preparation for the next part\n%reset_selective -f \"\\b\\\n(?!remove_and_classify\\b)\\\n(?!sort_explanations_by_importance\\b)\\\n(?!show_samples\\b)\\\n(?!show_attribution_overlay\\b)\\\n(?!plt\\b)\\\n(?!auc\\b)\\\n(?!rac_score\\b)\\\nw+\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:16:58.982979Z","iopub.execute_input":"2024-11-12T22:16:58.983363Z","iopub.status.idle":"2024-11-12T22:16:58.990027Z","shell.execute_reply.started":"2024-11-12T22:16:58.983319Z","shell.execute_reply":"2024-11-12T22:16:58.989201Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.2 Putting your evaluation function to use\n\nSo your evaluation function works. Great job! Now, the centered Gaussian was really a very naive explanation. Can we do better than that? Let's see: we will implement two other methods and find out whether they make a difference.\n\nFor this part, we will use a different dataset (CUB) and a different model (ResNet50). As CUB is not a standard PyTorch dataset, we added a bit of functionality to it for our experiments. Loading the dataset takes a bit (roughly 3 min).","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:16:58.99468Z","iopub.execute_input":"2024-11-12T22:16:58.995004Z","iopub.status.idle":"2024-11-12T22:16:59.001642Z","shell.execute_reply.started":"2024-11-12T22:16:58.994964Z","shell.execute_reply":"2024-11-12T22:16:59.000768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# prepare the dataset\n\nfrom tml2425_xai.resnet50 import resnet50\nfrom tml2425_xai.xai_utils import load_cub_test, model_accuracy, centered_gaussian\n\ncub_test = load_cub_test()\nnum_classes = 200 # 200 Bird species in CUB dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:16:59.002589Z","iopub.execute_input":"2024-11-12T22:16:59.002871Z","iopub.status.idle":"2024-11-12T22:18:56.142967Z","shell.execute_reply.started":"2024-11-12T22:16:59.002841Z","shell.execute_reply":"2024-11-12T22:18:56.142094Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"show_samples(cub_test, 8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:18:56.238183Z","iopub.execute_input":"2024-11-12T22:18:56.23865Z","iopub.status.idle":"2024-11-12T22:18:56.595175Z","shell.execute_reply.started":"2024-11-12T22:18:56.238601Z","shell.execute_reply":"2024-11-12T22:18:56.594218Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Important:** As mentioned during the lecture, there is an architectural change to the classic ResNet50 in the last layers in the provided model. Usually, a ResNet ends with a global average pooling layer before a dense layer, followed by a softmax. This is equivalent to changing the last layers to a 1x1 convolutional layer, global average pooling followed by softmax. With this architecture change, it is simpler to extract CAM.","metadata":{}},{"cell_type":"code","source":"resnet = resnet50(dataset_name='CUB',\n                    pretrained=False,\n                    num_classes=num_classes,\n                    large_feature_map=False,\n                    use_bn=True)\nckpt = torch.load('tml2425_xai_models/cam_cub_checkpoint.pth.tar')\nresnet.load_state_dict(ckpt[\"state_dict\"])\nresnet.to(device)\nresnet.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:18:56.596589Z","iopub.execute_input":"2024-11-12T22:18:56.59699Z","iopub.status.idle":"2024-11-12T22:18:57.352389Z","shell.execute_reply.started":"2024-11-12T22:18:56.596948Z","shell.execute_reply":"2024-11-12T22:18:57.351444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sanity check for CUB\n\ncub_accuracy = model_accuracy(resnet, cub_test)\nassert cub_accuracy == 0.798\nprint(f'Accuracy on the test set: {cub_accuracy:.3f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:18:57.353492Z","iopub.execute_input":"2024-11-12T22:18:57.353827Z","iopub.status.idle":"2024-11-12T22:18:59.859914Z","shell.execute_reply.started":"2024-11-12T22:18:57.353795Z","shell.execute_reply":"2024-11-12T22:18:59.858938Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This will come in handy.\n\nfrom tqdm import tqdm\n\ndef get_explanations(explanation_function, model, dataset):\n    \"\"\"Computes the explanations for the whole dataset specified in dataset\n\n    :param explanation_function: python function that takes arguments model, dataset, idx\n    :param model: model to be explained\n    :param dataset: dataset to be used to explain the model\n    \"\"\"\n    explanations = []\n    for idx in tqdm(range(len(dataset))):\n        e = explanation_function(model, dataset, idx)\n        assert e.shape == dataset[0][0].shape[-2:]\n        explanations.append(e)\n    return torch.stack(explanations, dim=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:18:59.861508Z","iopub.execute_input":"2024-11-12T22:18:59.861909Z","iopub.status.idle":"2024-11-12T22:18:59.867636Z","shell.execute_reply.started":"2024-11-12T22:18:59.861865Z","shell.execute_reply":"2024-11-12T22:18:59.866917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Example. Visualizing the gaussian baseline as an attribution explanation overlay.\nshow_attribution_overlay(cub_test.data[2], centered_gaussian(224, 224))","metadata":{"execution":{"iopub.status.busy":"2024-11-12T22:18:59.868604Z","iopub.execute_input":"2024-11-12T22:18:59.869197Z","iopub.status.idle":"2024-11-12T22:19:00.155867Z","shell.execute_reply.started":"2024-11-12T22:18:59.86916Z","shell.execute_reply":"2024-11-12T22:19:00.154872Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.2.0  Evaluate Gaussian map baseline\n\nSimilar to what we did in 1.1, except that now we use the CUB dataset instead.","metadata":{}},{"cell_type":"code","source":"# Evaluation of gaussian map baseline\n# First, get the explanations\ncub_test = load_cub_test()\n\nbaseline_explanations = torch.stack([torch.Tensor(centered_gaussian(224,224))]*len(cub_test), dim=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:19:00.157347Z","iopub.execute_input":"2024-11-12T22:19:00.158123Z","iopub.status.idle":"2024-11-12T22:19:32.116507Z","shell.execute_reply.started":"2024-11-12T22:19:00.15808Z","shell.execute_reply":"2024-11-12T22:19:32.115625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# then remove-and-classify\nimport time\nstart = time.time()\ncub_test = load_cub_test()\nk = 10000\nbaseline_removal_performances = remove_and_classify(resnet, cub_test, baseline_explanations, k)\nbaseline_removal_performances.insert(0, cub_accuracy)\nprint(time.time() - start)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:19:32.117874Z","iopub.execute_input":"2024-11-12T22:19:32.118342Z","iopub.status.idle":"2024-11-12T22:20:23.569982Z","shell.execute_reply.started":"2024-11-12T22:19:32.118299Z","shell.execute_reply":"2024-11-12T22:20:23.568988Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import auc\n# Inspect the results\nrac_score = auc(range(len(baseline_removal_performances)), baseline_removal_performances)\nrac_score_norm = rac_score / auc(range(len(baseline_removal_performances)), [cub_accuracy]*len(baseline_removal_performances))\nprint(f\"The remove and classify score is {rac_score_norm: .3f}\")\nimport matplotlib.pyplot as plt\nplt.plot(baseline_removal_performances)\nplt.ylabel('Model accuracy')\nplt.xlabel('Feature removal step (k=100)')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:20:23.57135Z","iopub.execute_input":"2024-11-12T22:20:23.571746Z","iopub.status.idle":"2024-11-12T22:20:23.79646Z","shell.execute_reply.started":"2024-11-12T22:20:23.571688Z","shell.execute_reply":"2024-11-12T22:20:23.795563Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.2.1 Implement input gradient explanations (10 pts)\n\nFirst, you will implement the vanilla gradient explanation method as a baseline to compare to (10 points). Write a function to get the saliency map from [Simonyan et al. (2013)](http://arxiv.org/abs/1312.6034) as a local explanation.","metadata":{}},{"cell_type":"code","source":"# TODO: 10 points\n\ndef saliency(model, dataset, sample_idx):\n    \"\"\"Computes the saliency map of the predicted class as a feature attribution explanation.\n    From Simonyan et al. (2013)\n\n    :param model: predictive model\n    :param dataset: dataset containing the instance to be explained\n    :param sample_idx: ID of the instance to be explained\n    :returns: saliency map of shape (224, 224) in case of CUB\n    \"\"\"\n    # Tip: Look at the assumptions for RGB images in the paper.\n    image, _ = dataset[sample_idx]\n    image = image.to(device)\n    image = image.unsqueeze(0) # to get the batch size dimension\n    #### >>>> PUT YOUR SOLUTION HERE <<<<\n    #### >>>> END OF YOUR SOLUTION <<<<\n    return saliency_map.cpu()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:20:23.797582Z","iopub.execute_input":"2024-11-12T22:20:23.797897Z","iopub.status.idle":"2024-11-12T22:20:23.804667Z","shell.execute_reply.started":"2024-11-12T22:20:23.797866Z","shell.execute_reply":"2024-11-12T22:20:23.803698Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"saliency_attribution = saliency(resnet, cub_test, 0)\nprint(saliency_attribution.shape)\n\nshow_attribution_overlay(cub_test.data[0], saliency_attribution)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:20:23.821833Z","iopub.execute_input":"2024-11-12T22:20:23.822497Z","iopub.status.idle":"2024-11-12T22:20:24.480706Z","shell.execute_reply.started":"2024-11-12T22:20:23.822454Z","shell.execute_reply":"2024-11-12T22:20:24.479845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluation of saliency\ncub_test = load_cub_test()\n\n# First, get the explanations\nsaliency_explanations = get_explanations(saliency, resnet, cub_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:20:24.481986Z","iopub.execute_input":"2024-11-12T22:20:24.482307Z","iopub.status.idle":"2024-11-12T22:21:19.815192Z","shell.execute_reply.started":"2024-11-12T22:20:24.482274Z","shell.execute_reply":"2024-11-12T22:21:19.814205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# then remove-and-classify\ncub_test = load_cub_test()\n\nk = 10000\nsaliency_removal_performances = remove_and_classify(resnet, cub_test, saliency_explanations, k)\nsaliency_removal_performances.insert(0, cub_accuracy)\n\n# Inspect the results\nrac_score = auc(range(len(saliency_removal_performances)), saliency_removal_performances)\nrac_score_norm = rac_score / auc(range(len(saliency_removal_performances)), [cub_accuracy]*len(saliency_removal_performances))\nprint(f\"The remove and classify score is {rac_score_norm: .3f}\")\n\nplt.plot(saliency_removal_performances)\nplt.ylabel('Model accuracy')\nplt.xlabel('Feature removal step (k=2500)')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:21:19.816582Z","iopub.execute_input":"2024-11-12T22:21:19.817246Z","iopub.status.idle":"2024-11-12T22:21:41.26367Z","shell.execute_reply.started":"2024-11-12T22:21:19.817199Z","shell.execute_reply":"2024-11-12T22:21:41.262773Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.2.2 Implement CAM (10 pts)","metadata":{}},{"cell_type":"markdown","source":"Next, you will implement the feature attribution explanation method [CAM by Zhou et al. (2016)](http://ieeexplore.ieee.org/document/7780688/).\n\n","metadata":{}},{"cell_type":"code","source":"# TODO: 10 points\n\ndef class_activation_map(model, dataset, sample_idx):\n    \"\"\"Gets the class activation map of the predicted class as a feature attribution explanation from the last convolutional layer of adapted ResNet model.\n    Originally from Zhou et al. (2016)\n\n    :param model: Adapted ResNet model in with 1x1 convolution\n    :param dataset: dataset containing the instance to be explained\n    :param sample_idx: ID of the instance to be explained\n    :returns: CAM of shape (224, 224) in case of CUB\n    \"\"\"\n    # Tip: use the hook method to extract the activations of particular layers\n    # Hook method below from https://discuss.pytorch.org/t/how-can-l-load-my-best-model-as-a-feature-extractor-evaluator/17254/6\n    activation = {}\n    def get_activation(name):\n        def hook(model, input, output):\n            activation[name] = output.detach()\n        return hook\n    image, _ = dataset[sample_idx]\n    image = image.to(device)\n    image = image.unsqueeze(0) # to get the batch size dimension\n    #### >>>> PUT YOUR SOLUTION HERE <<<<\n    #### >>>> END OF YOUR SOLUTION <<<<","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:21:41.264865Z","iopub.execute_input":"2024-11-12T22:21:41.265185Z","iopub.status.idle":"2024-11-12T22:21:41.271499Z","shell.execute_reply.started":"2024-11-12T22:21:41.265153Z","shell.execute_reply":"2024-11-12T22:21:41.27049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cam = class_activation_map(resnet, cub_test, 12)\n\nshow_attribution_overlay(cub_test.data[0], cam)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:21:41.285071Z","iopub.execute_input":"2024-11-12T22:21:41.285426Z","iopub.status.idle":"2024-11-12T22:21:41.540703Z","shell.execute_reply.started":"2024-11-12T22:21:41.285378Z","shell.execute_reply":"2024-11-12T22:21:41.53969Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluation of CAM\nimport matplotlib.pyplot as plt\n\n# First, get the explanations\ncam_explanations = get_explanations(class_activation_map, resnet, cub_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:21:41.542136Z","iopub.execute_input":"2024-11-12T22:21:41.542783Z","iopub.status.idle":"2024-11-12T22:21:51.52088Z","shell.execute_reply.started":"2024-11-12T22:21:41.542737Z","shell.execute_reply":"2024-11-12T22:21:51.519875Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# then remove-and-classify.\ncub_test = load_cub_test()\nk = 10000\ncam_removal_performances = remove_and_classify(resnet, cub_test, cam_explanations, k)\ncam_removal_performances.insert(0, cub_accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:21:51.522326Z","iopub.execute_input":"2024-11-12T22:21:51.522718Z","iopub.status.idle":"2024-11-12T22:22:42.571226Z","shell.execute_reply.started":"2024-11-12T22:21:51.522674Z","shell.execute_reply":"2024-11-12T22:22:42.570209Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Inspect the results\nfrom sklearn.metrics import auc\n\nrac_score = auc(range(len(cam_removal_performances)), cam_removal_performances)\nrac_score_norm = rac_score / auc(range(len(cam_removal_performances)), [cub_accuracy]*len(cam_removal_performances))\nprint(f\"The remove and classify score is {rac_score_norm: .3f}\")\n\nplt.plot(cam_removal_performances)\nplt.ylabel('Model accuracy')\nplt.xlabel('Feature removal step (k=10000)')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.3 Discussion (20 pts)\n\nThis kind of exercise aims to train you in scientific argumentation. In well-written research papers, you will often see results reported in roughly the same format as we ask you to adopt below.\n\n**Question**: Introduce the motivation for the experiment(s) in 1. Clearly state the research question, and the experimental setting. (4 points)\n\n**TODO your answer:**\n\n**Question**: Describe the results *factually* (i.e., do not draw any conclusions yet -- just share what you observe and find interesting). Use a combination of visual inspection and quantitative analysis. Make sure to point to specific data points in plots, tables etc. (4 points)\n\n**TODO your answer:**\n\n**Question**: Draw conclusion(s). Was the research question (that you stated above) answered? Why or why not? (4 points)\n\n**TODO your answer:**\n\n**Question**: What does the evaluation say about CAM and its comparison with baseline approaches? (4 points)\n\n**TODO your answer:**\n\n**Question**: What could be the limitations of the remove-and-classify approach used here? Does it make sense to, for instance, weigh different parts of the AUC differently? (4 points)\n\n**TODO your answer:**","metadata":{}},{"cell_type":"code","source":"# Remove all defined variables from memory for the next exercise\n# from https://www.skillsugar.com/how-to-delete-variables-functions-from-memory-in-python\n\nfor element in dir():\n    if element[0:2] != \"__\":\n        del globals()[element]\n\ndel element","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:22:42.841576Z","iopub.execute_input":"2024-11-12T22:22:42.841961Z","iopub.status.idle":"2024-11-12T22:22:43.05609Z","shell.execute_reply.started":"2024-11-12T22:22:42.841918Z","shell.execute_reply":"2024-11-12T22:22:43.055077Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2 Explaining predictions with Training Data Attribution (TDA)\n\nIn this part of the exercise sheet we will fine-tune a tiny language model on a sentiment-analysis task, and analyze its predictions using Influence Functions. It is a classic Training Data Attribution method, first introduced in the context of deep neural networks in [Koh & Liang 2017](https://arxiv.org/abs/1703.04730).\n\n*WARNING: Influence functions are computationally intensive. We will retrain models many times in this part of the exercise sheet. Start early.*\n\n*Recommended start: 28/11/2024*","metadata":{}},{"cell_type":"markdown","source":"## 2.0 Fine-tune a tiny langauge model for text classification (no points to earn here)\n\nIn this exercise, we fine-tune a pre-trained [DistilBERT](https://huggingface.co/docs/transformers/model_doc/distilbert) language model to do sentiment analysis on the [Rotten tomatoes dataset](https://huggingface.co/datasets/rotten_tomatoes). This dataset contains positive and negative movie reviews and the task is to classify them. Each example is just one sentence.\n\nThis model is not state-of-the-art by a long shot, but hopefully by the end of this exercise sheet you will understand why we decided to go for a tiny model and a tiny dataset.\nThis exercise closely follows the [Huggingface task guide for text classification](https://huggingface.co/docs/transformers/tasks/sequence_classification). Don't hesitate to consult this guide and HF docs in general if something is not clear.\n\nYou don't need to code anything new yet. But make sure you understand what this code does.\nThis will be useful to you for 2 reasons:\n - You will use the functions defined here in the following exercises.\n - Fine-tuning a pre-trained language model is easy, fun and teaches you a useful skill as well as the basics of using the Huggingface transformers library.\n","metadata":{}},{"cell_type":"code","source":"# You will usually not find these libraries in your typical Colab / Kaggle environments\n!pip install transformers[torch] datasets evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:24:25.07371Z","iopub.execute_input":"2024-11-12T22:24:25.074201Z","iopub.status.idle":"2024-11-12T22:24:41.56188Z","shell.execute_reply.started":"2024-11-12T22:24:25.074122Z","shell.execute_reply":"2024-11-12T22:24:41.560499Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import the required libraries\nfrom collections import defaultdict\nimport datasets as ds\nimport evaluate as ev\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nimport transformers as tf\nfrom tqdm import tqdm\nfrom typing import Dict, List, Union, Optional, Tuple, Iterator, Any","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:24:41.564194Z","iopub.execute_input":"2024-11-12T22:24:41.564579Z","iopub.status.idle":"2024-11-12T22:25:03.736724Z","shell.execute_reply.started":"2024-11-12T22:24:41.564541Z","shell.execute_reply":"2024-11-12T22:25:03.735555Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Constants used later in the code\nMODEL_NAME = \"distilbert-base-uncased\"\nDATASET_NAME = \"rotten_tomatoes\"\nWEIGHT_DECAY = 0.01\nNUM_LABELS = None # Filled automatically\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:25:03.738157Z","iopub.execute_input":"2024-11-12T22:25:03.738814Z","iopub.status.idle":"2024-11-12T22:25:03.785229Z","shell.execute_reply.started":"2024-11-12T22:25:03.738775Z","shell.execute_reply":"2024-11-12T22:25:03.784081Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fixing random seeds for reproducibility\ndef apply_random_seed(random_seed):\n    np.random.seed(random_seed)\n    torch.manual_seed(random_seed)\n    torch.cuda.manual_seed(random_seed)\n    torch.cuda.manual_seed_all(random_seed)\n\napply_random_seed(2024)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:25:03.788169Z","iopub.execute_input":"2024-11-12T22:25:03.788593Z","iopub.status.idle":"2024-11-12T22:25:03.805336Z","shell.execute_reply.started":"2024-11-12T22:25:03.788555Z","shell.execute_reply":"2024-11-12T22:25:03.804208Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_train_and_test_data():\n    # Load the dataset from huggingface hub\n    dataset_dict = ds.load_dataset(DATASET_NAME)\n    assert \"train\" in dataset_dict.keys(), \"Dataset must contain 'train' split.\"\n    assert \"test\" in dataset_dict.keys(), \"Dataset must contain 'test' split.\"\n    assert \"text\" in dataset_dict[\"train\"].features.keys(), \"Dataset must contain a 'text' column. Preprocess it if needed.\"\n    assert \"label\" in dataset_dict[\"train\"].features.keys(), \"Dataset must contain a 'label' column. Preprocess it if needed.\"\n\n    global NUM_LABELS\n    NUM_LABELS = dataset_dict[\"train\"].features[\"label\"].num_classes\n    \n    # Preprocess the dataset\n    \n    # 1. Take a subset of the dataset. \n    # https://huggingface.co/docs/datasets/process#shard\n    dataset_dict[\"train\"] = dataset_dict[\"train\"].shard(num_shards=8, index=3)\n    dataset_dict[\"test\"] = dataset_dict[\"test\"].shard(num_shards=2, index=1)\n\n    # 2. Tokenize the dataset. This creates the input_ids and attention_mask columns.\n    # Consult https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt for an overview of tokenization.\n    tokenizer = tf.AutoTokenizer.from_pretrained(MODEL_NAME)\n\n    def preprocess_function(example):\n        return tokenizer(example[\"text\"], truncation=True)\n\n    dataset_dict = dataset_dict.map(preprocess_function, batched=True)\n\n    # 3. Convert the dataset to PyTorch tensors.\n    # Not usually necessary, but our Influence Function computation needs it.\n    dataset_dict[\"train\"].set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n    dataset_dict[\"test\"].set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n    return dataset_dict[\"train\"], dataset_dict[\"test\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:25:03.806728Z","iopub.execute_input":"2024-11-12T22:25:03.807169Z","iopub.status.idle":"2024-11-12T22:25:03.818017Z","shell.execute_reply.started":"2024-11-12T22:25:03.807098Z","shell.execute_reply":"2024-11-12T22:25:03.816928Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_default_model_on_dataset(dataset, eval_dataset=None):\n    # Suppress warnings and info logs\n    tf.logging.set_verbosity_error()\n\n    # Provide readable names for the labels\n    id2label = {i: label for i, label in enumerate(dataset.features[\"label\"].names)}\n    label2id = {label: i for i, label in id2label.items()}\n    # Download the model and the corresponding tokenizer\n    model = tf.AutoModelForSequenceClassification.from_pretrained(\n        MODEL_NAME, num_labels=NUM_LABELS, id2label=id2label, label2id=label2id\n    ).to(DEVICE)\n    tokenizer = tf.AutoTokenizer.from_pretrained(MODEL_NAME)\n\n    # Data collator pads the inputs to the maximum length in the batch.\n    # This is needed because the sentences in the dataset have different lengths.\n    data_collator = tf.DataCollatorWithPadding(tokenizer=tokenizer)\n\n    # We use the accuracy metric to evaluate the model, since the task is classification.\n    accuracy = ev.load(\"accuracy\")\n    def compute_metrics(eval_pred):\n        predictions, labels = eval_pred\n        predictions = np.argmax(predictions, axis=1)\n        return accuracy.compute(predictions=predictions, references=labels)\n\n    training_args = tf.TrainingArguments(\n        output_dir=\"outdir\",\n        learning_rate=4e-5,\n        per_device_train_batch_size=32,\n        per_device_eval_batch_size=32,\n        num_train_epochs=2,\n        weight_decay=WEIGHT_DECAY,\n        save_strategy=\"no\",\n        report_to=\"none\",\n        disable_tqdm=False if eval_dataset else True,\n        log_level=\"error\",\n        evaluation_strategy=\"epoch\" if eval_dataset else \"no\",\n    )\n    trainer = tf.Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=dataset,\n        eval_dataset=eval_dataset,\n        data_collator=data_collator,\n        tokenizer=tokenizer,\n        compute_metrics=compute_metrics,\n    )\n    # A hack to stop the trainer from printing the results after each epoch.\n    # Relevant because we will retrain the model a lot in this notebook.\n    trainer.remove_callback(tf.trainer_callback.PrinterCallback)\n\n    # Run the training.\n    train_res = trainer.train()\n    # Set verbosity back to warning\n    tf.logging.set_verbosity_warning()\n\n    return trainer.model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:25:03.819624Z","iopub.execute_input":"2024-11-12T22:25:03.820171Z","iopub.status.idle":"2024-11-12T22:25:03.835174Z","shell.execute_reply.started":"2024-11-12T22:25:03.820093Z","shell.execute_reply":"2024-11-12T22:25:03.834196Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data, test_data = load_train_and_test_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:25:03.836448Z","iopub.execute_input":"2024-11-12T22:25:03.836806Z","iopub.status.idle":"2024-11-12T22:25:07.550886Z","shell.execute_reply.started":"2024-11-12T22:25:03.836771Z","shell.execute_reply":"2024-11-12T22:25:07.549718Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Number of train examples: {len(train_data)}\")\nprint(f\"Number of test examples: {len(test_data)}\")\nexample = train_data[0]\nprint(example)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:25:07.552575Z","iopub.execute_input":"2024-11-12T22:25:07.553022Z","iopub.status.idle":"2024-11-12T22:25:07.606687Z","shell.execute_reply.started":"2024-11-12T22:25:07.552972Z","shell.execute_reply":"2024-11-12T22:25:07.605647Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We preprocessed the text inputs to be readable for the language model that we will now train.\n\nTo actually read the text in this example we would have to decode it with the tokenizer.\n\nNote that [CLS] at the start and [SEP] at the end were not part of the data. These are special tokens that are added by the BERT tokenizer.","metadata":{}},{"cell_type":"code","source":"tokenizer = tf.AutoTokenizer.from_pretrained(MODEL_NAME)\nprint(tokenizer.decode(example[\"input_ids\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:25:07.608062Z","iopub.execute_input":"2024-11-12T22:25:07.608539Z","iopub.status.idle":"2024-11-12T22:25:07.732091Z","shell.execute_reply.started":"2024-11-12T22:25:07.608485Z","shell.execute_reply":"2024-11-12T22:25:07.73093Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trained_model = train_default_model_on_dataset(train_data, eval_dataset=test_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:25:07.736789Z","iopub.execute_input":"2024-11-12T22:25:07.737178Z","iopub.status.idle":"2024-11-12T22:25:21.462403Z","shell.execute_reply.started":"2024-11-12T22:25:07.737117Z","shell.execute_reply":"2024-11-12T22:25:21.461348Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The model achieves around 80% accuracy on the test set. Now let's try to use [the huggingface pipelines](https://huggingface.co/docs/transformers/main_classes/pipelines) to classify some text.","metadata":{}},{"cell_type":"code","source":"text = \"If you sometimes go to the movies to have fun, this movie is not a good place to start.\"\n\nclassifier = tf.pipeline(\"sentiment-analysis\", model=trained_model, tokenizer=tokenizer, device=DEVICE)\n\nclassifier(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:25:21.463874Z","iopub.execute_input":"2024-11-12T22:25:21.464299Z","iopub.status.idle":"2024-11-12T22:25:21.50208Z","shell.execute_reply.started":"2024-11-12T22:25:21.464259Z","shell.execute_reply":"2024-11-12T22:25:21.500921Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.1 Evaluate influence functions by retraining (10 points)\n\nInfluence functions are designed to be an approximation of the difference in loss after leave-one-out retraining. However, the theory only proves that this works for strictly convex models. For our task, we have to resort to empirical evaluation.\n\nIn this exercise, we will evaluate our implementation of Influence Functions.\nWe will do this by comparing the confidence of the model in the correct answer before and after retraining without influential samples.\nWhat you should expect: When you remove helpful samples, the probability of correct answer should decrease. This is because in our definition of the influence of the training sample $z_j$ on the test sample $z$:\n$IF(z_j, z) \\approx L(z, \\theta_{\\setminus j}) - L(z, \\theta)$, so positive influence means removing a given training sample would increase the\nloss on the test sample.\n\nRemoving harmful samples should increase the probability of correct answer. Removing random data should only show a small downward trend.\n\nTo achieve this, we will:\n - Pick a small set of test points\n - For each test point we will:\n    - Compute the model's confidence in correct answer\n    - Compute the influences of the training samples\n    - Retrain the model while removing 10, 20, 30 and 50 % of influential samples of each kind\n        - Filter the datasets and use the function ```train_default_model_on_dataset``` from 2.0\n    - Compute the model's confidence in correct answer after retraining\n - Average the results over test points\n - Plot the results\n    - Plotting is done for you. To see how it looks like and the needed format, we provide```dummy_results_dict``` in the plotting code.\n     Change the plotting code to use the actual ```results_dict``` when you're done with the computation.\n - Make sure that you measure the time needed to execute the full evaluation and record it. You will report it in the Discussion part of this exercise.\n\nWe also provide a dummy influence function, on which you can test your evaluation function. Later, in 2.2, we will write real influence functions.","metadata":{}},{"cell_type":"markdown","source":"First, let's see what the result of the influence function computation should look like using a dummy variable, `dummy_results_dict`.","metadata":{}},{"cell_type":"code","source":"removed_amounts = [0.1, 0.2, 0.3, 0.5]\n\ndef plot_influence_function_evaluation(results_dict):\n    fig, ax = plt.subplots()\n    colors = {\"Helpful\": 'tab:green', \"Harmful\": 'tab:orange',\"Random\": 'tab:blue'}\n    \n    for key, value in results_dict.items():\n        means = [np.mean(value[amount]) for amount in removed_amounts]\n        ax.plot(removed_amounts, means, '-o', label=f\"Removing {key}\", color=colors[key])\n    \n    ax.set_xlabel('Percentage of Examples Removed (%)')\n    ax.set_ylabel('Average Confidence Difference (%)')\n    ax.set_title('Impact of Removing Examples on Correct Answer Confidence')\n    ax.set_xticks(removed_amounts)\n    x_tick_labels = [f\"{int(x*100)}%\" for x in removed_amounts]\n    ax.set_xticklabels(x_tick_labels)\n    ax.legend()\n    \n    plt.show()\n \n\"\"\"results_dict is a dictionary with the keys \n    - \"Helpful\" (describing the influence of removing the most positively influential training examples), \n    - \"Harmful\" (describing the influence of removing the most negatively influential training examples, \n    - \"Random\" (describing the influence of removing samples in random order).\n\n    Each value in itself is a dict. Let's take the value corresponding to \"Helpful\", for example.\n    Each subkey here is a floating point number denoting the amount of (in this case, the most influential) training samples removed.\n    And then, the value corresponding to each subkey is a list with as many elements as the nuumber of test samples (2 in this case).\n    So, 0.1: [-1, -2] denotes that removing the top 10% helpful samples resulted in confidence decreases of 1% and 2% for the given test samples, respectively.\n    Similarly, 0.3: [3, 4] under \"Harmful\" denotes that removing the top 30% most harmful samples resulted in confidence increases of 3% and 4% for the given test samples, respectively.\n    When plotting, we average over the influences on all test samples.\n\"\"\"\ndummy_results_dict = {\n    \"Helpful\": {0.1: [-1, -2], 0.2: [-2, -3], 0.3: [-3, -4], 0.5: [-4, -5 ]},\n    \"Harmful\": {0.1: [1, 2], 0.2: [2, 3], 0.3: [3, 4], 0.5: [4, 5]},\n    \"Random\": {0.1: [0, 0], 0.2: [0, 0], 0.3: [0, 0], 0.5: [0, 0]},\n}\nplot_influence_function_evaluation(dummy_results_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:25:42.240921Z","iopub.execute_input":"2024-11-12T22:25:42.242006Z","iopub.status.idle":"2024-11-12T22:25:42.612119Z","shell.execute_reply.started":"2024-11-12T22:25:42.241956Z","shell.execute_reply":"2024-11-12T22:25:42.6108Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\ndef dummy_influence_function(model, tokenizer, test_inputs, train_data, knn_indices=None):\n    # Generate random influence scores for each training example\n    influence_scores = {i: np.random.uniform(-1, 1) for i in range(len(train_data))}\n    # Return the influence scores and a placeholder for any additional info (e.g., confidence scores)\n    return influence_scores, None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:27:46.060017Z","iopub.execute_input":"2024-11-12T22:27:46.061155Z","iopub.status.idle":"2024-11-12T22:27:46.068293Z","shell.execute_reply.started":"2024-11-12T22:27:46.06108Z","shell.execute_reply":"2024-11-12T22:27:46.067065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TODO: 3 points\n\ndef get_confidence_of_correct_answer(model, example):\n    \"\"\"Get the probability of the correct answer in example under the model.\n    Recall that each `example` is a dict with keys \"input_ids\", \"labels\", \n    \"\"\"\n    #### >>>> PUT YOUR SOLUTION HERE <<<<\n    #### >>>> END OF YOUR SOLUTION <<<<\n    return confidence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:27:46.25422Z","iopub.execute_input":"2024-11-12T22:27:46.255179Z","iopub.status.idle":"2024-11-12T22:27:46.262389Z","shell.execute_reply.started":"2024-11-12T22:27:46.255088Z","shell.execute_reply":"2024-11-12T22:27:46.261224Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TODO: 7 points\n\ndef evaluate_by_retraining(\n    influence_function,\n    train_data,\n    training_function,\n    test_data,\n    model,\n    tokenizer,\n    use_knn: bool = True,\n):\n\n    if use_knn:\n        print(\"Using KNN Speedup.\")\n        print(\"Emebedding train data...\")\n        embedded_train_data = embed_training_dataset(model, tokenizer, train_data)\n\n    print(\"Training on original dataset\")\n    trained_model = training_function(train_data)\n\n    results_dict = {\n        \"Helpful\": defaultdict(list),\n        \"Harmful\": defaultdict(list),\n        \"Random\": defaultdict(list),\n    }\n    \n    test_example_indices = [x for x in range(10, 13)]\n\n    # Measure the time\n    start_ts = time.time()\n\n    for i, idx in enumerate(test_example_indices):\n        print(f\"Running test example {i} / {len(test_example_indices)}\")\n        test_example = {\n            \"input_ids\": test_data[\"input_ids\"][idx].view(1, -1).to(DEVICE),\n            \"attention_mask\": test_data[\"attention_mask\"][idx].view(1, -1).to(DEVICE),\n            \"labels\" : test_data[\"label\"][idx].view(1, -1).to(DEVICE),\n        }\n\n        if use_knn:\n            print(f\"Searching for the k nearest neighbors\")\n            knn_indices = get_knn_indices(model, embedded_train_data, test_example, k=300)\n            \n        # Compute confidence of correct answer before retraining\n        c_pre = get_confidence_of_correct_answer(trained_model, test_example)\n    \n        #### >>>> PUT YOUR SOLUTION HERE <<<<\n        #### >>>> END OF YOUR SOLUTION <<<<\n\n    print(\"\\nResults:\\n\")\n    for key in results_dict:\n        for amount in removed_amounts:\n            print(f\"{key}: Removed {amount} examples. Average confidence difference: {np.mean(results_dict[key][amount]):.2f}% (std: {np.std(results_dict[key][amount]):.2f})\")\n    print(f\"Time elapsed: {time.time() - start_ts:.2f}s\")\n\n    return results_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:27:46.388302Z","iopub.execute_input":"2024-11-12T22:27:46.38932Z","iopub.status.idle":"2024-11-12T22:27:46.401213Z","shell.execute_reply.started":"2024-11-12T22:27:46.389272Z","shell.execute_reply":"2024-11-12T22:27:46.399946Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"random_influence_results_dict = evaluate_by_retraining(\n    dummy_influence_function,\n    train_data,\n    train_default_model_on_dataset,\n    test_data,\n    trained_model,\n    tokenizer,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:27:46.683642Z","iopub.execute_input":"2024-11-12T22:27:46.684508Z","iopub.status.idle":"2024-11-12T22:31:23.69367Z","shell.execute_reply.started":"2024-11-12T22:27:46.684462Z","shell.execute_reply":"2024-11-12T22:31:23.692513Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Try plotting the results obtained above\nplot_influence_function_evaluation(random_influence_results_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:31:23.696635Z","iopub.execute_input":"2024-11-12T22:31:23.697145Z","iopub.status.idle":"2024-11-12T22:31:24.047547Z","shell.execute_reply.started":"2024-11-12T22:31:23.697054Z","shell.execute_reply":"2024-11-12T22:31:24.046455Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As you can see, there is no real trend to see here. Remember that we used a random influence function with the purpose of testing your evaluation function. Next, we will write real influence functions, and you will be able to see some patterns emerge.","metadata":{}},{"cell_type":"markdown","source":"## 2.2 Implementing an influence function\n\nLet's jump right into it.","metadata":{}},{"cell_type":"markdown","source":"## 2.2.1 Influence Function: LISSA (10 pts)\n\nThis small exercise aims to simulate real-world research experience. In machine learning, we often want to reproduce results from papers that we read. \nWe do that to check the validity of those results, use them as baselines for comparisons, or just build on top of them. \nThe ability to navigate a research paper codebase is thus crucial for your success as machine learning users and developers.\n\nBelow you will find the code for computing Influence Functions, adapted (mostly simplified) from the [FastIF repository](https://github.com/salesforce/fast-influence-functions).\nThis is the repository for the [FastIF paper](https://aclanthology.org/2021.emnlp-main.808.pdf).\nBefore reading the code or the paper you might find it helpful to watch the [short video from the author](https://aclanthology.org/2021.emnlp-main.808.mp4).\n\nAfter the code there is a small example for using it on the model that we have just trained in Section 2.0.\n\nYour goal here is to read the code and answer the Questions below.","metadata":{}},{"cell_type":"code","source":"def get_loss(model: torch.nn.Module, inputs: Dict[str, torch.Tensor]) -> float:\n    for k, v in inputs.items():\n        inputs[k] = v.to(DEVICE)\n    outputs = model(**inputs)\n    loss = outputs.loss\n\n    # In PyTorch, weight-decay loss and gradients are calculated in optimizers\n    # rather in nn.Module, so we have to manually specify this for the loss here.\n    no_decay = [\"bias\", \"LayerNorm.weight\"]\n    weight_decay_loss = torch.cat([\n        param.square().view(-1)\n        for name, param in model.named_parameters()\n        if not any(nd in name for nd in no_decay)\n    ]).sum() * WEIGHT_DECAY\n    loss = loss + weight_decay_loss\n    return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:31:24.048874Z","iopub.execute_input":"2024-11-12T22:31:24.049262Z","iopub.status.idle":"2024-11-12T22:31:24.057643Z","shell.execute_reply.started":"2024-11-12T22:31:24.049222Z","shell.execute_reply":"2024-11-12T22:31:24.056472Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_gradients(\n        model: torch.nn.Module, inputs: Dict[str, torch.Tensor], params_filter: Optional[List[str]],\n) -> List[torch.FloatTensor]:\n\n    if params_filter is None:\n        params_filter = []\n\n    model.zero_grad()\n    loss = get_loss(model=model, inputs=inputs)\n\n    filtered_params = [\n        param for name, param in model.named_parameters() if name not in params_filter\n    ]\n    return torch.autograd.grad(outputs=loss, inputs=filtered_params, create_graph=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:31:24.060553Z","iopub.execute_input":"2024-11-12T22:31:24.060921Z","iopub.status.idle":"2024-11-12T22:31:24.071775Z","shell.execute_reply.started":"2024-11-12T22:31:24.060883Z","shell.execute_reply":"2024-11-12T22:31:24.070698Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_hessian_vector_products(\n        model: torch.nn.Module,\n        inputs: Dict[str, torch.Tensor],\n        vectors: torch.FloatTensor,\n        params_filter: Optional[List[str]],\n) -> List[torch.FloatTensor]:\n\n    if params_filter is None:\n        params_filter = []\n\n    model.zero_grad()\n    loss = get_loss(model=model, inputs=inputs)\n\n    filtered_params = [\n        param for name, param in model.named_parameters() if name not in params_filter\n    ]\n    grad_tuple = torch.autograd.grad(\n        outputs=loss,\n        inputs=filtered_params,\n        create_graph=True\n    )\n\n    model.zero_grad()\n    grad_grad_tuple = torch.autograd.grad(\n        outputs=grad_tuple,\n        inputs=filtered_params,\n        grad_outputs=vectors,\n        only_inputs=True\n    )\n\n    return grad_grad_tuple","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:31:24.073203Z","iopub.execute_input":"2024-11-12T22:31:24.073601Z","iopub.status.idle":"2024-11-12T22:31:24.083664Z","shell.execute_reply.started":"2024-11-12T22:31:24.073562Z","shell.execute_reply":"2024-11-12T22:31:24.082605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_s_test(\n        model: torch.nn.Module,\n        test_inputs: Dict[str, torch.Tensor],\n        train_data_loader: torch.utils.data.DataLoader,\n        params_filter: Optional[List[str]],\n        damp: float,\n        scale: float,\n) -> List[torch.FloatTensor]:\n\n    v = compute_gradients(model=model, inputs=test_inputs, params_filter=params_filter)\n    # Technically, it's hv^-1\n    last_estimate = list(v).copy()\n    for i, inputs in enumerate(train_data_loader):\n        this_estimate = compute_hessian_vector_products(\n            model=model,\n            vectors=last_estimate,\n            inputs=inputs,\n            params_filter=params_filter,\n        )\n        # Recursively caclulate h_estimate\n        # https://github.com/dedeswim/pytorch_influence_functions/blob/master/pytorch_influence_functions/influence_functions/hvp_grad.py#L118\n        with torch.no_grad():\n            new_estimate = [\n                a + (1 - damp) * b - c / scale\n                for a, b, c in zip(v, last_estimate, this_estimate)\n            ]\n\n        last_estimate = new_estimate\n\n    # Reference: https://github.com/kohpangwei/influence-release/blob/master/influence/genericNeuralNet.py#L475\n    # Do this for each iteration of estimation # Since we use one estimation, we put this at the end\n    inverse_hvp = [X / scale for X in last_estimate]\n    return inverse_hvp\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:31:24.085337Z","iopub.execute_input":"2024-11-12T22:31:24.086338Z","iopub.status.idle":"2024-11-12T22:31:24.097469Z","shell.execute_reply.started":"2024-11-12T22:31:24.086296Z","shell.execute_reply":"2024-11-12T22:31:24.096443Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_influences(\n        model: torch.nn.Module,\n        tokenizer: tf.PreTrainedTokenizer,\n        test_inputs: Dict[str, torch.Tensor],\n        train_data: ds.Dataset,\n        knn_indices: Optional[set] = None,\n        params_filter: Optional[List[str]] = None,\n        s_test_damp: float = 3e-5,\n        s_test_scale: float = 1e4,\n        s_test_iterations: int = 1,\n        precomputed_s_test: Optional[List[torch.FloatTensor]] = None,\n) -> Tuple[Dict[int, float], Dict[int, Dict], List[torch.FloatTensor]]:\n\n    data_collator = tf.DataCollatorWithPadding(tokenizer=tokenizer)\n\n    # Create data loaders from the huggingface dataset\n    instance_train_data_loader = DataLoader(\n        train_data, batch_size=1, sampler=SequentialSampler(train_data), collate_fn=data_collator\n    )\n    batch_train_data_loader = DataLoader(\n        train_data, batch_size=32, sampler=RandomSampler(train_data), collate_fn=data_collator\n    )\n\n    if s_test_iterations < 1: raise ValueError(\"`s_test_iterations` must >= 1\")\n\n    if precomputed_s_test is not None:\n        s_test = precomputed_s_test\n    else:\n        s_test = None\n        for _ in range(s_test_iterations):\n            iter_s_test = compute_s_test(\n                model=model,\n                test_inputs=test_inputs,\n                train_data_loader=batch_train_data_loader,\n                params_filter=params_filter,\n                damp=s_test_damp,\n                scale=s_test_scale,\n            )\n\n            # On first iteration use the computed value, on further iterations sum the values across runs\n            s_test = iter_s_test if s_test is None else [a + b for a, b in zip(s_test, iter_s_test)]\n\n        # Do the averaging\n        s_test = [a / s_test_iterations for a in s_test]\n\n    influences = {}\n    for index, train_inputs in enumerate(tqdm(instance_train_data_loader)):\n        if knn_indices is not None and index not in knn_indices: continue\n\n        grad_z = compute_gradients(model=model, inputs=train_inputs, params_filter=params_filter)\n        with torch.no_grad():\n            influence = [torch.sum(x * y) for x, y in zip(grad_z, s_test)]\n\n        influences[index] = sum(influence).item()\n\n    return influences, s_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:31:24.098764Z","iopub.execute_input":"2024-11-12T22:31:24.099149Z","iopub.status.idle":"2024-11-12T22:31:24.117718Z","shell.execute_reply.started":"2024-11-12T22:31:24.099063Z","shell.execute_reply":"2024-11-12T22:31:24.116658Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example for using the influence functions\ntext = \"I greatly enjoyed this movie and will recommend it to everyone!\"\ntest_example = tokenizer(text, return_tensors=\"pt\")\ntest_example['labels'] = torch.tensor([1])\ntest_example.to(DEVICE)\n\n# Compute influences\ninfluences, _ = compute_influences(\n    model=trained_model, tokenizer=tokenizer, test_inputs=test_example, train_data=train_data\n)\n\n# Take the 5 most influential examples\ntop_5_idc = sorted(influences, key=influences.get, reverse=True)[:5]\ntop_5_t_i_l = [\n    (\n        tokenizer.decode(train_data[idx][\"input_ids\"], skip_special_tokens=True),\n        influences[idx],\n        train_data[idx][\"label\"]\n     )\n    for idx in top_5_idc\n]\n_ = [print(f\"Label: {l}, Influence: {i:.2f}, Text: {t}\") for (t, i, l) in top_5_t_i_l]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:31:24.119258Z","iopub.execute_input":"2024-11-12T22:31:24.119693Z","iopub.status.idle":"2024-11-12T22:32:10.816631Z","shell.execute_reply.started":"2024-11-12T22:31:24.119654Z","shell.execute_reply":"2024-11-12T22:32:10.815494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Let's evaluate this influence function\nlissa_results_dict = evaluate_by_retraining(\n    compute_influences,\n    train_data,\n    train_default_model_on_dataset,\n    test_data,\n    trained_model,\n    tokenizer,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:32:10.81797Z","iopub.execute_input":"2024-11-12T22:32:10.818332Z","iopub.status.idle":"2024-11-12T22:38:12.982571Z","shell.execute_reply.started":"2024-11-12T22:32:10.818295Z","shell.execute_reply":"2024-11-12T22:38:12.981385Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_influence_function_evaluation(lissa_results_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:38:12.986584Z","iopub.execute_input":"2024-11-12T22:38:12.986929Z","iopub.status.idle":"2024-11-12T22:38:13.331207Z","shell.execute_reply.started":"2024-11-12T22:38:12.986894Z","shell.execute_reply":"2024-11-12T22:38:13.330172Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Questions\n\n**Question 1** (1 point)\n\nWhich equation from the [FastIF paper](https://aclanthology.org/2021.emnlp-main.808.pdf) does the function ```compute_s_test``` represent? A number is enough.\n\n**TODO your answer:**\n\n**Question 2** (2.5 points)\n\nWhy does the function ```compute_s_test``` need a ```train_data_loader``` parameter if it computes something for the test sample, as indicated by its name?\n\n**TODO your answer:**\n\n**Question 3** (4 points)\n\nSection 3.3 of the paper describes the LISSA approximation to compute inverse hessian vector product (IHVP) in three steps: **Step 1**, **Step 2**, and **Step 3**.\nLocate each step in the code and cite it in your answer.\n\n*Example*:\n\n**Step 1**\n```\nthe_code = cited_in_markdown()\n``````\n**TODO your answer:**\n\n**Question 4** (2.5 points)\n\nIf you wanted to speed-up the computation by only considering the gradient to some subset of the NN weights, which parameter\nof the function ```compute_influences``` would you use and how?\nA short description in words is enough, no need to implement it.\n\n**TODO your answer:**","metadata":{}},{"cell_type":"markdown","source":"## 2.2.2 Speed up the computations using kNN (10 points)\n\nYour goal in this exercise is to speed up the search for influential samples by only running the search on a subset of\nthe training set that is expected to be influential, as described [in section 3.2 of the paper](https://aclanthology.org/2021.emnlp-main.808.pdf).\n\nWe will do this by first running a k-nearest-neighbors search over the full dataset. Then we will compute the influences of the found neighbors by providing the ```knn_indices``` parameter to the ```compute_influences``` function. *Note that IHVP is still computed using the full training set.* This two-step procedure is expected to be faster while still finding the influential samples.\n\n**Evaluation**\n\nAfter implementing this part, please plot the results (code provided below).\nYou should see evaluation results comparable with full-search, but faster.\nRecord the time needed to run the evaluation and report the time comparison with the full search.\n\n**How to search for neighbors**\n\nTo implement the nearest neighbor search we need to measure similarity between a test sample $x$ and a train\nsample $x_j$. This is often done in machine learning by embedding both in a vector space and computing the distance\nbetween the 2 vectors. A typical way to construct such embeddings is to take the last layer activations of our neural network. This is a common trick for deep metric learning: the assumption is that this way we obtain a good representation of our sample in a lower-dimensional space that preserves the semantics.\n\nIn our task, both $x$ and $x_j$ are sequences. Moreover, they have varying lengths, and a transformer model generates an embedding for each of the tokens at every layer.\n\nThe solution that is often adopted when one needs to embed an entire sentence with a BERT-type model is to take\nthe last layer embedding of the ```[CLS]``` token. You have already encountered this token in part 2.0 of this exercise.\nIf everything works correctly, it should be the first token of the input. If you want to check for it, you can find the\nID of this token by ```tokenizer.cls_token_id```.","metadata":{}},{"cell_type":"code","source":"# Let's look at the trained model again\ntrained_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:38:13.332441Z","iopub.execute_input":"2024-11-12T22:38:13.332764Z","iopub.status.idle":"2024-11-12T22:38:13.341262Z","shell.execute_reply.started":"2024-11-12T22:38:13.332729Z","shell.execute_reply":"2024-11-12T22:38:13.340119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# To give you hints for solving the upcoming questions\nout = trained_model(**test_example, output_hidden_states=True)\nprint(len(out.hidden_states))\nprint(out.hidden_states[-1].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:38:13.342609Z","iopub.execute_input":"2024-11-12T22:38:13.342939Z","iopub.status.idle":"2024-11-12T22:38:13.363973Z","shell.execute_reply.started":"2024-11-12T22:38:13.342903Z","shell.execute_reply":"2024-11-12T22:38:13.362934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TODO: 2 points\n\ndef embed_one_example(model, example):\n    \"\"\"Computes the last layer embedding of the [CLS] token for one example.\"\"\"\n    #### >>>> PUT YOUR SOLUTION HERE <<<<\n    #### >>>> END OF YOUR SOLUTION <<<<\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:38:13.365091Z","iopub.execute_input":"2024-11-12T22:38:13.365442Z","iopub.status.idle":"2024-11-12T22:38:13.370301Z","shell.execute_reply.started":"2024-11-12T22:38:13.365407Z","shell.execute_reply":"2024-11-12T22:38:13.369055Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TODO: 2 points\n\ndef embed_training_dataset(model, tokenizer, train_dataset):\n    \"\"\"Create a list of embeddings for the training dataset.\n    To be used for the kNN search.\n    \"\"\"\n    data_collator = tf.DataCollatorWithPadding(tokenizer=tokenizer)\n    train_dataloader = DataLoader(\n        train_data, batch_size=1, sampler=SequentialSampler(train_data), collate_fn=data_collator\n    )\n    embeddings = []\n    #### >>>> PUT YOUR SOLUTION HERE <<<<\n    #### >>>> END OF YOUR SOLUTION <<<<\n    return embeddings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:38:13.382262Z","iopub.execute_input":"2024-11-12T22:38:13.382619Z","iopub.status.idle":"2024-11-12T22:38:13.392882Z","shell.execute_reply.started":"2024-11-12T22:38:13.382583Z","shell.execute_reply":"2024-11-12T22:38:13.391834Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TODO: 6 points\n\ndef get_knn_indices(model, embedded_train_data, test_input, k=100):\n    \"\"\"Returns the set of indices of the k nearest neighbors of test_input in the training dataset.\"\"\"\n    #### >>>> PUT YOUR SOLUTION HERE <<<<\n    #### >>>> END OF YOUR SOLUTION <<<<\n    return knn_indices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:38:13.408575Z","iopub.execute_input":"2024-11-12T22:38:13.408891Z","iopub.status.idle":"2024-11-12T22:38:13.418326Z","shell.execute_reply.started":"2024-11-12T22:38:13.408856Z","shell.execute_reply":"2024-11-12T22:38:13.417388Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Let's evaluate the kNN speedup\n\nlissa_knn_results_dict = evaluate_by_retraining(\n    compute_influences,\n    train_data,\n    train_default_model_on_dataset,\n    test_data,\n    trained_model,\n    tokenizer,\n    use_knn=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:38:13.431535Z","iopub.execute_input":"2024-11-12T22:38:13.431904Z","iopub.status.idle":"2024-11-12T22:43:49.030691Z","shell.execute_reply.started":"2024-11-12T22:38:13.431866Z","shell.execute_reply":"2024-11-12T22:43:49.029644Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the results\nplot_influence_function_evaluation(lissa_knn_results_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T22:43:49.210478Z","iopub.execute_input":"2024-11-12T22:43:49.210945Z","iopub.status.idle":"2024-11-12T22:43:49.529262Z","shell.execute_reply.started":"2024-11-12T22:43:49.210903Z","shell.execute_reply":"2024-11-12T22:43:49.528173Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.3 Discussion (20 pts)\n\nSimilarly to 1.3, here we ask you to answer some questions about the experiments in this section.\n\n**Question 1**: How big was the speed-up that you observed? Explain your observations. (5 points)\n\n**TODO your answer**:\n\n**Question 1**:  Does this type of evaluation make sense to you? What are its pros and cons? (5 points)\n\n**TODO your answer**:\n\n**Question 1**: In this type of soundness evaluation we use random removal as a baseline. What could some other reasonable baselines be? (5 points)\n\n**TODO your answer**:\n\n**Question 1**: Try to come up with 2 practical applications of Training Data Attribution not mentioned in the lecture and explain why they are useful. (Citing existing work not cited in the lecture is welcome.) (5 points)\n\n**TODO your answer**:\n\n*(No points, feedback question)* What is your personal opinion on TDA methods? Do you see an application for them in your own projects? If yes - how, and if not - why? How would you compare them with feature-based attribution methods?","metadata":{}},{"cell_type":"markdown","source":"# 3 (Bonus) Short Paper Review (10 points)\n\nIn this bonus task, your task is to write a short review for **one** of the following papers:\n- [Analyzing Chain-of-Thought Prompting in Large Language Models via\nGradient-based Feature Attributions](https://arxiv.org/abs/2307.13339).\n- [Driving with LLMs: Fusing Object-Level Vector Modality for Explainable Autonomous Driving](https://arxiv.org/pdf/2310.01957.pdf)\n- [On Gradient-like Explanation under a Black-box Setting: When Black-box Explanations Become as Good as White-box](https://arxiv.org/pdf/2308.09381.pdf)\n\nBelow are a few questions to consider in a review as inspiration (Slightly adapted from [ICML'22 reviewer guide](https://drive.google.com/file/d/15hPTA64h31ShaoybLWeU3moZan7zVbr_/view))\n- A concise summary of the paper\n    - What problem is addressed in the paper?\n    - Why does the problem matter?\n    - What is the key to the solution? What is the main contribution?\n    - Do the experiments sufficiently support the claims?\n- A clear statement of strengths and weaknesses\n    - What are the key contributions and why do they matter?\n    - What aspects of the paper most need improvement?\n- A comprehensive check of potential fundamental flaws in the paper\n    - Are the assumptions and theories (mathematically) sound?\n    - Are the experiments scientifically sound and valid?\n    - Is the problem addressed trivial?\n\nWhen reviewing, adress the paper from the angle of Trustworthy AI, specifically focusing on the topic of Explainability.","metadata":{}}]}